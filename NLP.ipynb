{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION\n",
    "\n",
    "Welcome to this Jupyter Notebook where we will delve into various Natural Language Processing (NLP) techniques. Through hands-on exploration, we aim to gain a deeper understanding of this evolving NLP paradigm and its practical applications. Join me on this journey as we unravel the intricacies of language processing and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classify the spam using Naive Bayes\n",
    "\n",
    "In this section, we'll dive into the fascinating task of spam classification using the Naive Bayes algorithm. Spam classification is a classic problem in the realm of Natural Language Processing (NLP) and machine learning. By employing the Naive Bayes approach, we aim to build a model that can effectively distinguish between spam and non-spam messages based on their textual content. Let's walk through the process of preprocessing the data, training the Naive Bayes classifier, and evaluating its performance. By the end of this section, you'll have a solid grasp of how Naive Bayes can be harnessed for practical NLP tasks like spam detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip'\n",
    "data_file = 'SMSSpamCollection'\n",
    "\n",
    "response = requests.get(url)\n",
    "filename = url.split(\"/\")[-1]\n",
    "\n",
    "with open(filename, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "with zipfile.ZipFile(filename, 'r') as zip:\n",
    "    zip.extractall('')\n",
    "\n",
    "data = pd.read_table(data_file,\n",
    "                    header = 0,\n",
    "                    names = ['type', 'message'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>ham</td>\n",
       "      <td>I anything lor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>spam</td>\n",
       "      <td>You are a winner U have been specially selecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>ham</td>\n",
       "      <td>Come to mu, we're sorting out our narcotics si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                            message\n",
       "4478   ham                                    I anything lor.\n",
       "159   spam  You are a winner U have been specially selecte...\n",
       "270    ham  Come to mu, we're sorting out our narcotics si..."
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see a sample of our data\n",
    "\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5571</td>\n",
       "      <td>5571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4824</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                 message\n",
       "count   5571                    5571\n",
       "unique     2                    5168\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4824                      30"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# description of our data\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have 5571 rows with two columns each. One column is the message, and the other is the type of the message, spam or ham (no spam).\n",
    "\n",
    "Now, we will transform our data, so we will be able to work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Perrosato\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Perrosato\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# we tokenize our message\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "data['tokens'] = data['message'].apply(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "data['tokens'] = data['tokens'].apply(lambda x: [palabra for palabra in x if palabra not in stop])\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "data['tokens'] = data['tokens'].apply(lambda x: [stemmer.stem(item) for item in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>message</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fuck babe, I miss you sooooo much !! I wish yo...</td>\n",
       "      <td>[fuck, babe, ,, i, miss, sooooo, much, !, !, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok can...</td>\n",
       "      <td>[ok, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>ham</td>\n",
       "      <td>I accidentally brought em home in the box</td>\n",
       "      <td>[i, accident, brought, em, home, box]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ugh its been a long day. I'm exhausted. Just w...</td>\n",
       "      <td>[ugh, long, day, ., i, 'm, exhaust, ., just, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thankyou so much for the call. I appreciate yo...</td>\n",
       "      <td>[thankyou, much, call, ., i, appreci, care, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                                            message  \\\n",
       "1620  ham  Fuck babe, I miss you sooooo much !! I wish yo...   \n",
       "3385  ham                                          Ok can...   \n",
       "5217  ham          I accidentally brought em home in the box   \n",
       "873   ham  Ugh its been a long day. I'm exhausted. Just w...   \n",
       "2191  ham  Thankyou so much for the call. I appreciate yo...   \n",
       "\n",
       "                                                 tokens  \n",
       "1620  [fuck, babe, ,, i, miss, sooooo, much, !, !, i...  \n",
       "3385                                          [ok, ...]  \n",
       "5217              [i, accident, brought, em, home, box]  \n",
       "873   [ugh, long, day, ., i, 'm, exhaust, ., just, w...  \n",
       "2191     [thankyou, much, call, ., i, appreci, care, .]  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see our data again\n",
    "\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the dataset, we need to transform it into a matrix format. A common representation is the term-document matrix or feature matrix, where each row corresponds to a document (data point) and each column represents a unique feature. In your case, where you're dealing with text data for spam classification, you might use techniques like TF-IDF (Term Frequency-Inverse Document Frequency) to convert text into numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the functions\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# re-join the strings\n",
    "\n",
    "data['tokens'] = data['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# split the data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data['tokens'],\n",
    "    data['type'],\n",
    "    test_size = 0.2\n",
    ")\n",
    "\n",
    "# create the vectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    strip_accents = 'ascii',\n",
    "    lowercase = True\n",
    ")\n",
    "\n",
    "# fit vectorizer\n",
    "\n",
    "vectorizer_fit = vectorizer.fit(x_train)\n",
    "x_train_transformed = vectorizer_fit.transform(x_train)\n",
    "x_test_transformed = vectorizer_fit.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the matrix prepared, we can apply the Naive Bayes algorithm for classification. Naive Bayes is a probabilistic algorithm that makes predictions based on the calculated probabilities of a data point belonging to different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train has 0.9849953658640458 of accuracy, with the confusion matrix:\n",
      " [[3856   11]\n",
      " [  16  573]]\n",
      "\n",
      "The test has 0.9583382934539635 of accuracy, with the confusion matrix:\n",
      " [[956   1]\n",
      " [ 13 145]]\n"
     ]
    }
   ],
   "source": [
    "# import the functions\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "# train the model\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes_fit = naive_bayes.fit(x_train_transformed, y_train)\n",
    "\n",
    "# make the predictions\n",
    "\n",
    "train_predict = naive_bayes_fit.predict(x_train_transformed)\n",
    "test_predict = naive_bayes_fit.predict(x_test_transformed)\n",
    "\n",
    "# get the results\n",
    "\n",
    "print(f\"The train has {balanced_accuracy_score(y_train, train_predict)} of accuracy, with the confusion matrix:\\n\",\n",
    "        f\"{confusion_matrix(y_train, train_predict)}\")\n",
    "\n",
    "print(f\"\\nThe test has {balanced_accuracy_score(y_test, test_predict)} of accuracy, with the confusion matrix:\\n\",\n",
    "        f\"{confusion_matrix(y_test, test_predict)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will create a function that is able to predict if a message is spam:\n",
    "\n",
    "def spam_detector(message_vect = None):\n",
    "\n",
    "    if message_vect == None:\n",
    "        message = str(input(\"Insert your message: \"))\n",
    "    else:\n",
    "        message = message_vect\n",
    "    message_token = nltk.word_tokenize(message)\n",
    "    message_clean = [word for word in message_token if word not in stop]\n",
    "    message_clean = [stemmer.stem(item) for item in message_clean]\n",
    "\n",
    "    message = ' '.join(message_clean)\n",
    "\n",
    "    message_vect = vectorizer_fit.transform([message])\n",
    "    \n",
    "    return(naive_bayes_fit.predict(message_vect)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of the use of the detector\n",
    "\n",
    "spam_detector('You just won a brand new car. To get if for free, just click in this link')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sentimetal analysis\n",
    "\n",
    "In the upcoming section, we're set to explore the captivating realm of sentiment analysis using advanced machine learning techniques. Sentiment analysis, a pivotal application of Natural Language Processing (NLP), involves discerning the emotional tone underlying textual content. Our focus turns towards unraveling the sentiments expressed within text, ranging from positive and neutral to negative. Armed with cutting-edge methods, we'll delve into the process of preparing data, constructing robust sentiment analysis models, and evaluating their effectiveness. By immersing ourselves in this section, you'll gain a profound understanding of how to wield these techniques for real-world NLP tasks, enabling you to develop models adept at deciphering and classifying sentiments within text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (1.5.16)\n",
      "Requirement already satisfied: tqdm in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from kaggle) (4.64.1)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from kaggle) (2022.9.14)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from kaggle) (1.26.11)\n",
      "Requirement already satisfied: bleach in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from kaggle) (2.28.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from bleach->kaggle) (21.3)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (from packaging->bleach->kaggle) (3.0.9)\n",
      "twitter-sentiment-analysis-hatred-speech.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "# install kaggle and download the data\n",
    "\n",
    "!pip install kaggle\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "!kaggle datasets download -d arkhoshghalb/twitter-sentiment-analysis-hatred-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the two datasets\n",
    "\n",
    "train = pd.read_csv(\"train.csv\", index_col = 'id')\n",
    "test = pd.read_csv(\"test.csv\", index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11181</th>\n",
       "      <td>0</td>\n",
       "      <td>@user ahhhh might have guessed   #euro2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19640</th>\n",
       "      <td>0</td>\n",
       "      <td>(1/3) #samanthabee may be the only #woman in #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7059</th>\n",
       "      <td>0</td>\n",
       "      <td>it's arrived!! my free scarf from @user for re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19128</th>\n",
       "      <td>0</td>\n",
       "      <td>i finally found a way how to delete old tweets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9746</th>\n",
       "      <td>0</td>\n",
       "      <td>sunday morning beach run   #weekend #running #...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "id                                                             \n",
       "11181      0         @user ahhhh might have guessed   #euro2016\n",
       "19640      0  (1/3) #samanthabee may be the only #woman in #...\n",
       "7059       0  it's arrived!! my free scarf from @user for re...\n",
       "19128      0  i finally found a way how to delete old tweets...\n",
       "9746       0  sunday morning beach run   #weekend #running #..."
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see an example of the train\n",
    "\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44081</th>\n",
       "      <td>hot new release! swiftly sharpens the fang  #r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37592</th>\n",
       "      <td>#playinggames   buffalo simulation: buffalo fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35404</th>\n",
       "      <td>@user happy it's friday #tgif #kitten #catsof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46521</th>\n",
       "      <td>@user i always think that at 1st .. i'm sure w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46743</th>\n",
       "      <td>@user danish #imam tried for #antijewish incit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet\n",
       "id                                                      \n",
       "44081  hot new release! swiftly sharpens the fang  #r...\n",
       "37592  #playinggames   buffalo simulation: buffalo fo...\n",
       "35404   @user happy it's friday #tgif #kitten #catsof...\n",
       "46521  @user i always think that at 1st .. i'm sure w...\n",
       "46743  @user danish #imam tried for #antijewish incit..."
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see an example of the test \n",
    "\n",
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this NLP project, our goal is to develop a model that can determine whether tweets are racist or not. The dataset we're working with contains labeled tweets, where the label is assigned as follows:\n",
    "\n",
    "- **Label 1**: Tweets that are identified as racist.\n",
    "- **Label 0**: Tweets that are not racist.\n",
    "\n",
    "We'll be using a machine learning approach to build and train a classifier for this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweet-preprocessor in c:\\users\\perrosato\\anaconda3\\lib\\site-packages (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "# import some libraries \n",
    "\n",
    "!pip install tweet-preprocessor\n",
    "import re\n",
    "import preprocessor as p\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the tweets\n",
    "\n",
    "def clean_tweets(df):\n",
    "  tempArr = []\n",
    "  for line in df:\n",
    "    tmpL = p.clean(line)\n",
    "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) \n",
    "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "    tempArr.append(tmpL)\n",
    "  return tempArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the tweets\n",
    "\n",
    "train['tweet'] = clean_tweets(train['tweet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train['tweet'],\n",
    "                                                    train['label'],\n",
    "                                                    test_size = 0.2,\n",
    "                                                    shuffle = True \n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train the vectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english', binary = True)\n",
    "\n",
    "vectorizer.fit(train['tweet'])\n",
    "\n",
    "x_train_vec = vectorizer.transform(x_train)\n",
    "x_test_vec = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the algorithm and create the model\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "svm = svm.SVC(kernel = 'linear')\n",
    "\n",
    "svm.fit(x_train_vec, y_train)\n",
    "\n",
    "y_train_pred = svm.predict(x_train_vec)\n",
    "y_test_pred = svm.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is:  95.15 %.\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"The accuracy score is: \", round(accuracy_score(y_true = y_test, y_pred = y_test_pred) * 100, 2), '%.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our model trained, we will take the test data to make an example of how to predict if a tweet or a group of them are or not racists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 42346 tweet is not racist.\n"
     ]
    }
   ],
   "source": [
    "# we take a random tweet to do the example\n",
    "\n",
    "import random\n",
    "\n",
    "num = random.randint(test.index.min(), test.index.max())\n",
    "\n",
    "tweet = test.loc[num]['tweet']\n",
    "\n",
    "tweet_cleaned = clean_tweets([tweet])\n",
    "tweet_vec = vectorizer.transform(tweet_cleaned)\n",
    "tweet_pred = svm.predict(tweet_vec)\n",
    "\n",
    "if tweet_pred[0] == 1:\n",
    "    predict = \"is\"\n",
    "else:\n",
    "    predict = \"is not\"\n",
    "\n",
    "print(f'The {num} tweet {predict} racist.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also evaluate our model with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31963</th>\n",
       "      <td>to find</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31964</th>\n",
       "      <td>want everyone to see the new and heres why</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31965</th>\n",
       "      <td>safe ways to heal your</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31966</th>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31967</th>\n",
       "      <td>rd to my amazing hilarious eli ahmir uncle dav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  predict\n",
       "id                                                               \n",
       "31963                                            to find        0\n",
       "31964         want everyone to see the new and heres why        0\n",
       "31965                           safe ways to heal your          0\n",
       "31966  is the hp and the cursed child book up for res...        0\n",
       "31967  rd to my amazing hilarious eli ahmir uncle dav...        0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a column with the predict\n",
    "\n",
    "test['tweet'] = clean_tweets(test['tweet'])\n",
    "test_vect = vectorizer.transform(test['tweet'])\n",
    "test['predict'] = svm.predict(test_vect)\n",
    "\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 873 racist and 16324 not racists.\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy\n",
    "\n",
    "print(f\"There are {len(test.loc[test['predict'] == 1])} racist and {len(test) - len(test.loc[test['predict'] == 1])} not racists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43803</th>\n",
       "      <td>get familiar w  the elite roots of richard spe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40214</th>\n",
       "      <td>the impression given was the houses would have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39172</th>\n",
       "      <td>is not an  racism is people based on race to j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44497</th>\n",
       "      <td>im genuinely disappointed that a performer as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33911</th>\n",
       "      <td>thank fuck for that i was running out of vids ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  predict\n",
       "id                                                               \n",
       "43803  get familiar w  the elite roots of richard spe...        1\n",
       "40214  the impression given was the houses would have...        1\n",
       "39172  is not an  racism is people based on race to j...        1\n",
       "44497  im genuinely disappointed that a performer as ...        1\n",
       "33911  thank fuck for that i was running out of vids ...        1"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some of the racist tweets \n",
    "\n",
    "test.loc[test['predict'] == 1].sample(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
